# -*- coding: utf-8 -*-
"""PCA&LR_deaths/million

Automatically generated by Colaboratory.

"""

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.dates as mdate
import pandas as pd
import ipywidgets as widgets
from ipywidgets import interact
import os

"""Download fixed data from a shared folder so that we all use the same data."""

# Download data
import gdown
work_dir = os.path.abspath("/content")
work_file = os.path.join(work_dir, "owid-covid-data.csv")
data_file_link = "https://drive.google.com/uc?id=1zWIKCrWWeEGjEe5Q88i21Lu9Cet_TzdQ"
gdown.download(data_file_link, work_file, quiet=False)

infname = "owid-covid-data.csv"
indata = pd.read_csv(infname)
type(indata)
indata.head()

"""Basic information about the dataset:"""

print("Shape of original data: " + str(indata.shape))
print("Columns of original data: ")
print(indata.columns)

#20-7-2020 data
df=indata
df["date"] = pd.to_datetime(df["date"], format="%Y-%m-%d")
#print(df["date"])
df = df.loc[df['date'] == '2020-07-10']
#df.head()
df.shape

#remove nans
#percent nulls
df["location"].drop_duplicates()
workdata=df.drop(columns=['continent','date','iso_code','total_tests', 'new_tests','total_tests_per_thousand','new_deaths','new_cases','new_deaths_per_million','new_tests_per_thousand','new_tests_smoothed','new_tests_smoothed_per_thousand','tests_units','extreme_poverty','handwashing_facilities','stringency_index','female_smokers','male_smokers','hospital_beds_per_thousand','diabetes_prevalence'])
workdata = workdata[workdata.location != 'World']
#(100*workdata.isnull().sum())/len(workdata)
workdata
workdata.isnull().sum(axis=1).tolist()
##remove all null rows? - only 17 remaining
newdata=workdata[workdata.isnull().sum(axis=1) == 0]
len(newdata)
newdata.head()
newdata.shape

from sklearn.model_selection import train_test_split
#newdata.columns
#'location', 'total_cases', 'new_cases', 'total_deaths', 'total_cases_per_million', 'new_cases_per_million','total_deaths_per_million', 'new_deaths_per_million', 'population','population_density', 'median_age', 'aged_65_older', 'aged_70_older',
       #'gdp_per_capita', 'cardiovasc_death_rate', 'life_expectancy']

#targets - total_deaths
vars=newdata.drop(columns=['total_deaths','total_deaths_per_million','location'])
targs=newdata[['total_deaths','total_deaths_per_million']]
trainx, testx, trainy, testy = train_test_split(vars, targs, test_size=0.2, random_state=0)

from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn import preprocessing
import matplotlib.pyplot as plt
scaler = StandardScaler() 
trainx_scale = scaler.fit_transform(trainx)
testx_scale = scaler.fit_transform(testx)

pca = PCA(.95)
pca.fit(trainx_scale)

print(pca.explained_variance_ratio_)
#plt.bar(np.arange(11), pca.explained_variance_ratio_[0:55])

print(np.cumsum(pca.explained_variance_ratio_))
plt.plot(np.cumsum(pca.explained_variance_ratio_))
plt.xlabel('number of components')
plt.ylabel('cumulative explained variance');

train_fit = pca.transform(trainx_scale)
test_fit = pca.transform(testx_scale)

from sklearn.linear_model import LinearRegression
from sklearn import metrics

regressor = LinearRegression() 
regressor.fit(train_fit, trainy['total_deaths_per_million'])

yhat=regressor.predict(test_fit)
regressor.score(test_fit, testy['total_deaths_per_million'])
#logisticRegr.score(testy['total_deaths'],yhat)
  
#log_loss(testy['total_deaths'],yhat)

print('Mean Absolute Error:', metrics.mean_absolute_error(testy['total_deaths_per_million'], yhat))  
print('Mean Squared Error:', metrics.mean_squared_error(testy['total_deaths_per_million'], yhat))  
print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(testy['total_deaths_per_million'], yhat)))

p = pd.DataFrame({'Actual': testy['total_deaths_per_million'], 'Predicted': yhat})
p.plot(kind='bar',figsize=(20,10))
plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')
plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')
plt.show()
plt.show()

x=newdata['location']
x.to_csv('filename.csv') 
from google.colab import files
files.download('filename.csv')